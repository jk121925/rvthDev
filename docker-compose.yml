version: "3.5"
services:
  mongodb:
    image: mongo:4.4.5
    restart: always
    container_name: mongodb
    ports:
      - "27017:27017"  # 호스트의 27018 포트와 컨테이너의 27018 포트 매핑
    volumes:
      - ./mongodb:/data/db
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: 1234
      MONGO_INITDB_DATABASE: rovothome_iot
    networks:
      - my-network

  kafka-gen:
    image: confluentinc/cp-kafka:7.3.3
    hostname: kafka-gen
    container_name: kafka-gen
    volumes:
      - ./scripts/create_cluster_id.sh:/tmp/create_cluster_id.sh
      - ./clusterID:/tmp/clusterID
    networks:
      - my-network
    command: "bash -c '/tmp/create_cluster_id.sh'"

  kafka1:
    image: confluentinc/cp-kafka:7.3.3
    hostname: kafka1
    container_name: kafka1
    ports:
      - "9092:9092"
    environment:
      KAFKA_LISTENERS: BROKER://kafka1:19092,EXTERNAL://0.0.0.0:9092,CONTROLLER://kafka1:39093
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka1:19092,EXTERNAL://localhost:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,BROKER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_PROCESS_ROLES: 'controller,broker'
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:39093,2@kafka2:39093,3@kafka3:39093'
      KAFKA_METADATA_LOG_SEGMENT_MS: 15000
      KAFKA_METADATA_MAX_RETENTION_MS: 1200000
      KAFKA_METADATA_LOG_MAX_RECORD_BYTES_BETWEEN_SNAPSHOTS: 2800
      # KAFKA_OPTS: -Djava.security.auth.login.config=/path/to/jaas.conf
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
    volumes:
      - ./kafka1-data:/var/lib/kafka/data
      - ./scripts/update_run.sh:/tmp/update_run.sh
      - ./clusterID:/tmp/clusterID
      # - ./path/to/jaas.conf:/path/to/jaas.conf
    networks:
      - my-network
    command: "bash -c '/tmp/update_run.sh && /etc/confluent/docker/run'"

  kafka2:
    image: confluentinc/cp-kafka:7.3.3
    hostname: kafka2
    container_name: kafka2
    ports:
      - "9093:9093"
    environment:
      KAFKA_LISTENERS: BROKER://kafka2:19092,EXTERNAL://0.0.0.0:9093,CONTROLLER://kafka2:39093
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka2:19092,EXTERNAL://localhost:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,BROKER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_PROCESS_ROLES: 'controller,broker'
      KAFKA_NODE_ID: 2
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:39093,2@kafka2:39093,3@kafka3:39093'
      KAFKA_METADATA_LOG_SEGMENT_MS: 15000
      KAFKA_METADATA_MAX_RETENTION_MS: 1200000
      KAFKA_METADATA_LOG_MAX_RECORD_BYTES_BETWEEN_SNAPSHOTS: 2800
      # KAFKA_OPTS: -Djava.security.auth.login.config=/path/to/jaas.conf
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
    volumes:
      - kafka2-data:/var/lib/kafka/data
      - ./scripts/update_run.sh:/tmp/update_run.sh
      - ./clusterID:/tmp/clusterID
      # - ./path/to/jaas.conf:/path/to/jaas.conf
    networks:
      - my-network
    command: "bash -c '/tmp/update_run.sh && /etc/confluent/docker/run'"

  kafka3:
    image: confluentinc/cp-kafka:7.3.3
    hostname: kafka3
    container_name: kafka3
    ports:
      - "9094:9094"
    environment:
      KAFKA_LISTENERS: BROKER://kafka3:19092,EXTERNAL://0.0.0.0:9094,CONTROLLER://kafka3:39093
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka3:19092,EXTERNAL://localhost:9094
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,BROKER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_PROCESS_ROLES: 'controller,broker'
      KAFKA_NODE_ID: 3
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:39093,2@kafka2:39093,3@kafka3:39093'
      KAFKA_METADATA_LOG_SEGMENT_MS: 15000
      KAFKA_METADATA_MAX_RETENTION_MS: 1200000
      KAFKA_METADATA_LOG_MAX_RECORD_BYTES_BETWEEN_SNAPSHOTS: 2800
      # KAFKA_OPTS: -Djava.security.auth.login.config=/path/to/jaas.conf
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
    volumes:
      - kafka3-data:/var/lib/kafka/data
      - ./scripts/update_run.sh:/tmp/update_run.sh
      - ./clusterID:/tmp/clusterID
      # - ./path/to/jaas.conf:/path/to/jaas.conf
    networks:
      - my-network
    command: "bash -c '/tmp/update_run.sh && /etc/confluent/docker/run'"

  kafka-connect:
    image: confluentinc/cp-kafka-connect:6.2.0
    container_name: kafka-connect
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka1:19092,kafka2:19092,kafka3:19092
      CONNECT_REST_ADVERTISED_HOST_NAME: localhost
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: kafka-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: kafka-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: kafka-connect-status
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
    volumes:
      - ./connectors/mongodb-kafka-connect-mongodb-1.10.1/lib/:/etc/kafka-connect/jars
      - ./path/to/local/mongo-kafka-connect-1.10.1-confluent.jar:/usr/share/java/kafka-connect/mongodb-connector.jar
      - ./path/to/local/connect-standalone.properties:/etc/kafka/connect-standalone.properties
      - ./log4j.properties:/etc/kafka/connect-log4j.properties
    networks:
      - my-network

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - 8080:8080 # Changed to avoid port clash with akhq
    depends_on:
      - kafka1
      - kafka2
      - kafka3
      # - kafka-connect
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:19092,kafka2:19092,kafka3:19092
      # KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: connect
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect:8083
      DYNAMIC_CONFIG_ENABLED: 'true'
    networks:
      - my-network

  prometheus:
    container_name: prometheus
    image: prom/prometheus
    ports:
      - 9090:9090
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml    
    networks:
      - my-network
  grafana:
    container_name: grafana
    image: grafana/grafana
    ports:
      - 3000:3000
    depends_on:
      - prometheus
    environment:
      GF_SECURITY_ADMIN_USER: root
      GF_SECURITY_ADMIN_PASSWORD: 1234
    volumes:
      - ./grafana-provisioning:/etc/grafana/provisioning
    networks:
      - my-network

  # mongodb-exporter:
  #   container_name: mongodb-exporter
  #   image: bitnami/mongodb-exporter
  #   ports:
  #     - 9216:9216
  #   environment:
  #     - MONGODB_URI=mongodb://root:1234@mongodb:27017  
  #     - MONGODB_EXPORTER_ENABLE_LEGACY_AUTH=true
  #     - MONGODB_EXPORTER_DISABLE_DEFAULT_METRICS=true
  #   command: 
  #     --mongodb.collstats-colls=rovothome_iot.iotSwitch
  #   networks:
  #     - my-network

  mongodb_exporter:
    container_name: mongodb-exporter
    image: percona/mongodb_exporter:0.31.2
    ports:
      - 9216:9216
    environment:
      - MONGODB_URI=mongodb://root:1234@localhost:27017/admin?authSource=root
      - COLLECTOR_DBSTATS=true
    networks:
      - my-network

networks:
  my-network:
    driver: bridge
    
volumes:
  kafka1-data:
  kafka2-data:
  kafka3-data:


  # influxdb:
  #   image: influxdb:latest
  #   env_file:
  #     - .env
  #   entrypoint: ["./entrypoint.sh"]
  #   volumes:
  #     - influxdb-storage:/var/lib/influxdb2:rw
  #   ports:
  #     - "8086:8086"
  # telegraf:
  #   image: telegraf:1.19
  #   restart: always
  #   volumes:
  #     - ./telegraf/telegraf.conf:/etc/telegraf/telegraf.conf:rw
  #   env_file:
  #     - .env
  #   depends_on:
  #     - influxdb
  # influxdb-storage:
  